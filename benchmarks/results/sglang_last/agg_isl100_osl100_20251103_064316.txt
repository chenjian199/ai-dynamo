================================================================================
DECODE TEST RESULTS - Concurrency: 1
Timestamp: 2025-11-03 06:43:30
Model: /home/bedicloud/models/deepseek-ai/DeepSeek-R1-Distill-Llama-8B
Service URL: http://127.0.0.1:8003
Input Length: 100, Output Length: 100
Status: SUCCESS
================================================================================

GENAI-PERF OUTPUT:
----------------------------------------
[2025-11-03 06:43:16] INFO     Detected passthrough args: ['-vv', '--max-threads=300']                                parser.py:865
[2025-11-03 06:43:16] INFO     Profiling these models:                                                          create_config.py:58
                               /home/bedicloud/models/deepseek-ai/DeepSeek-R1-Distill-Llama-8B                                     
[2025-11-03 06:43:16] INFO     Model name                                                               perf_analyzer_config.py:157
                               '/home/bedicloud/models/deepseek-ai/DeepSeek-R1-Distill-Llama-8B' cannot                            
                               be used to create artifact directory. Instead,                                                      
                               '_home_bedicloud_models_deepseek-ai_DeepSeek-R1-Distill-Llama-8B' will                              
                               be used.                                                                                            
[2025-11-03 06:43:16] INFO     Creating tokenizer for:                                                            subcommand.py:190
                               /home/bedicloud/models/deepseek-ai/DeepSeek-R1-Distill-Llama-8B                                     
[2025-11-03 06:43:19] INFO     Running Perf Analyzer : 'perf_analyzer -m                                           subcommand.py:98
                               /home/bedicloud/models/deepseek-ai/DeepSeek-R1-Distill-Llama-8B --async                             
                               --stability-percentage 999 --request-count 4 -i http -u http://127.0.0.1:8003                       
                               --concurrency-range 1 --service-kind openai --endpoint v1/chat/completions -vv                      
                               --max-threads=300 --input-data                                                                      
                               /tmp/simple_decode_test_1/_home_bedicloud_models_deepseek-ai_DeepSeek-R1-Distill-Ll                 
                               ama-8B-openai-chat-concurrency1/inputs.json --profile-export-file                                   
                               /tmp/simple_decode_test_1/_home_bedicloud_models_deepseek-ai_DeepSeek-R1-Distill-Ll                 
                               ama-8B-openai-chat-concurrency1/profile_export.json'                                                
[2025-11-03 06:43:25] INFO     Loading response data from                                                 profile_data_parser.py:66
                               '/tmp/simple_decode_test_1/_home_bedicloud_models_deepseek-ai_DeepSeek-R1-                          
                               Distill-Llama-8B-openai-chat-concurrency1/profile_export.json'                                      
[2025-11-03 06:43:25] INFO     Parsing total 4 requests.                                             llm_profile_data_parser.py:124
                                    NVIDIA GenAI-Perf | LLM Metrics                                     
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┓
┃                            Statistic ┃      avg ┃    min ┃      max ┃      p99 ┃      p90 ┃      p75 ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━┩
│             Time To First Token (ms) │   404.33 │  34.41 │   781.79 │   781.08 │   774.74 │   764.16 │
│            Time To Second Token (ms) │     4.17 │   0.00 │     5.83 │     5.82 │     5.74 │     5.61 │
│                 Request Latency (ms) │ 1,046.74 │ 670.33 │ 1,429.00 │ 1,428.30 │ 1,422.04 │ 1,411.61 │
│             Inter Token Latency (ms) │     6.56 │   6.40 │     6.61 │     6.61 │     6.61 │     6.61 │
│     Output Token Throughput Per User │   152.58 │ 151.34 │   156.18 │   156.03 │   154.75 │   152.61 │
│                    (tokens/sec/user) │          │        │          │          │          │          │
│      Output Sequence Length (tokens) │    99.00 │  99.00 │    99.00 │    99.00 │    99.00 │    99.00 │
│       Input Sequence Length (tokens) │   201.00 │ 201.00 │   201.00 │   201.00 │   201.00 │   201.00 │
│ Output Token Throughput (tokens/sec) │    94.11 │    N/A │      N/A │      N/A │      N/A │      N/A │
│         Request Throughput (per sec) │     0.95 │    N/A │      N/A │      N/A │      N/A │      N/A │
│                Request Count (count) │     4.00 │    N/A │      N/A │      N/A │      N/A │      N/A │
└──────────────────────────────────────┴──────────┴────────┴──────────┴──────────┴──────────┴──────────┘
[2025-11-03 06:43:29] INFO     Generating                                                                       json_exporter.py:64
                               /tmp/simple_decode_test_1/_home_bedicloud_models_deepseek-ai_DeepSeek-R1-Distill                    
                               -Llama-8B-openai-chat-concurrency1/profile_export_genai_perf.json                                   
[2025-11-03 06:43:29] INFO     Generating                                                                        csv_exporter.py:75
                               /tmp/simple_decode_test_1/_home_bedicloud_models_deepseek-ai_DeepSeek-R1-Distill-                   
                               Llama-8B-openai-chat-concurrency1/profile_export_genai_perf.csv                                     

----------------------------------------

================================================================================
================================================================================
DECODE TEST RESULTS - Concurrency: 10
Timestamp: 2025-11-03 06:43:49
Model: /home/bedicloud/models/deepseek-ai/DeepSeek-R1-Distill-Llama-8B
Service URL: http://127.0.0.1:8003
Input Length: 100, Output Length: 100
Status: SUCCESS
================================================================================

GENAI-PERF OUTPUT:
----------------------------------------
[2025-11-03 06:43:36] INFO     Detected passthrough args: ['-vv', '--max-threads=300']                                parser.py:865
[2025-11-03 06:43:36] INFO     Profiling these models:                                                          create_config.py:58
                               /home/bedicloud/models/deepseek-ai/DeepSeek-R1-Distill-Llama-8B                                     
[2025-11-03 06:43:36] INFO     Model name                                                               perf_analyzer_config.py:157
                               '/home/bedicloud/models/deepseek-ai/DeepSeek-R1-Distill-Llama-8B' cannot                            
                               be used to create artifact directory. Instead,                                                      
                               '_home_bedicloud_models_deepseek-ai_DeepSeek-R1-Distill-Llama-8B' will                              
                               be used.                                                                                            
[2025-11-03 06:43:36] INFO     Creating tokenizer for:                                                            subcommand.py:190
                               /home/bedicloud/models/deepseek-ai/DeepSeek-R1-Distill-Llama-8B                                     
[2025-11-03 06:43:39] INFO     Running Perf Analyzer : 'perf_analyzer -m                                           subcommand.py:98
                               /home/bedicloud/models/deepseek-ai/DeepSeek-R1-Distill-Llama-8B --async                             
                               --stability-percentage 999 --request-count 40 -i http -u http://127.0.0.1:8003                      
                               --concurrency-range 10 --service-kind openai --endpoint v1/chat/completions -vv                     
                               --max-threads=300 --input-data                                                                      
                               /tmp/simple_decode_test_10/_home_bedicloud_models_deepseek-ai_DeepSeek-R1-Distill-L                 
                               lama-8B-openai-chat-concurrency10/inputs.json --profile-export-file                                 
                               /tmp/simple_decode_test_10/_home_bedicloud_models_deepseek-ai_DeepSeek-R1-Distill-L                 
                               lama-8B-openai-chat-concurrency10/profile_export.json'                                              
[2025-11-03 06:43:43] INFO     Loading response data from                                                 profile_data_parser.py:66
                               '/tmp/simple_decode_test_10/_home_bedicloud_models_deepseek-ai_DeepSeek-R1                          
                               -Distill-Llama-8B-openai-chat-concurrency10/profile_export.json'                                    
[2025-11-03 06:43:43] INFO     Parsing total 40 requests.                                            llm_profile_data_parser.py:124
                                NVIDIA GenAI-Perf | LLM Metrics                                 
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┓
┃                            Statistic ┃      avg ┃    min ┃    max ┃    p99 ┃    p90 ┃    p75 ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━┩
│             Time To First Token (ms) │    56.85 │  19.20 │ 115.99 │ 115.98 │ 109.05 │  72.87 │
│            Time To Second Token (ms) │     6.23 │   0.00 │  20.46 │  19.14 │  10.28 │   8.28 │
│                 Request Latency (ms) │   733.74 │ 693.25 │ 792.64 │ 792.64 │ 784.36 │ 755.40 │
│             Inter Token Latency (ms) │     6.91 │   6.59 │   7.16 │   7.14 │   7.02 │   6.98 │
│     Output Token Throughput Per User │   144.82 │ 139.60 │ 151.79 │ 151.40 │ 148.88 │ 145.12 │
│                    (tokens/sec/user) │          │        │        │        │        │        │
│      Output Sequence Length (tokens) │    99.00 │  99.00 │  99.00 │  99.00 │  99.00 │  99.00 │
│       Input Sequence Length (tokens) │   200.90 │ 200.00 │ 201.00 │ 201.00 │ 201.00 │ 201.00 │
│ Output Token Throughput (tokens/sec) │ 1,319.88 │    N/A │    N/A │    N/A │    N/A │    N/A │
│         Request Throughput (per sec) │    13.33 │    N/A │    N/A │    N/A │    N/A │    N/A │
│                Request Count (count) │    40.00 │    N/A │    N/A │    N/A │    N/A │    N/A │
└──────────────────────────────────────┴──────────┴────────┴────────┴────────┴────────┴────────┘
[2025-11-03 06:43:48] INFO     Generating                                                                       json_exporter.py:64
                               /tmp/simple_decode_test_10/_home_bedicloud_models_deepseek-ai_DeepSeek-R1-Distil                    
                               l-Llama-8B-openai-chat-concurrency10/profile_export_genai_perf.json                                 
[2025-11-03 06:43:48] INFO     Generating                                                                        csv_exporter.py:75
                               /tmp/simple_decode_test_10/_home_bedicloud_models_deepseek-ai_DeepSeek-R1-Distill                   
                               -Llama-8B-openai-chat-concurrency10/profile_export_genai_perf.csv                                   

----------------------------------------

================================================================================
