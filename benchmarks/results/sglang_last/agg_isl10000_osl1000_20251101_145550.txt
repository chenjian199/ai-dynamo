================================================================================
DECODE TEST RESULTS - Concurrency: 1
Timestamp: 2025-11-01 15:01:52
Model: /home/bedicloud/models/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
Service URL: http://127.0.0.1:8003
Input Length: 10000, Output Length: 1000
Status: SUCCESS
================================================================================

GENAI-PERF OUTPUT:
----------------------------------------
[2025-11-01 14:55:51] INFO     Detected passthrough args: ['-vv',  parser.py:865
                               '--max-threads=300']                             
[2025-11-01 14:55:51] INFO     Profiling these models:       create_config.py:58
                               /home/bedicloud/models/deepse                    
                               ek-ai/DeepSeek-R1-Distill-Lla                    
                               ma-70B                                           
[2025-11-01 14:55:51] INFO     Model name            perf_analyzer_config.py:157
                               '/home/bedicloud/mode                            
                               ls/deepseek-ai/DeepSe                            
                               ek-R1-Distill-Llama-7                            
                               0B' cannot be used to                            
                               create artifact                                  
                               directory. Instead,                              
                               '_home_bedicloud_mode                            
                               ls_deepseek-ai_DeepSe                            
                               ek-R1-Distill-Llama-7                            
                               0B' will be used.                                
[2025-11-01 14:55:51] INFO     Creating tokenizer for:         subcommand.py:190
                               /home/bedicloud/models/deepseek                  
                               -ai/DeepSeek-R1-Distill-Llama-7                  
                               0B                                               
[2025-11-01 14:55:54] INFO     Running Perf Analyzer :          subcommand.py:98
                               'perf_analyzer -m                                
                               /home/bedicloud/models/deepseek-                 
                               ai/DeepSeek-R1-Distill-Llama-70B                 
                                --async --stability-percentage                  
                               999 --request-count 4 -i http -u                 
                               http://127.0.0.1:8003                            
                               --concurrency-range 1                            
                               --service-kind openai --endpoint                 
                               v1/chat/completions -vv                          
                               --max-threads=300 --input-data                   
                               /tmp/simple_decode_test_1/_home_                 
                               bedicloud_models_deepseek-ai_Dee                 
                               pSeek-R1-Distill-Llama-70B-opena                 
                               i-chat-concurrency1/inputs.json                  
                               --profile-export-file                            
                               /tmp/simple_decode_test_1/_home_                 
                               bedicloud_models_deepseek-ai_Dee                 
                               pSeek-R1-Distill-Llama-70B-opena                 
                               i-chat-concurrency1/profile_expo                 
                               rt.json'                                         
[2025-11-01 15:01:47] INFO     Loading response data   profile_data_parser.py:66
                               from                                             
                               '/tmp/simple_decode_tes                          
                               t_1/_home_bedicloud_mod                          
                               els_deepseek-ai_DeepSee                          
                               k-R1-Distill-Llama-70B-                          
                               openai-chat-concurrency                          
                               1/profile_export.json'                           
[2025-11-01 15:01:47] INFO     Parsing total 4    llm_profile_data_parser.py:124
                               requests.                                        
                        NVIDIA GenAI-Perf | LLM Metrics                         
┏━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┓
┃ Statist… ┃      avg ┃      min ┃       max ┃      p99 ┃       p90 ┃      p75 ┃
┡━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━┩
│  Time To │ 34,844.… │   510.74 │ 69,574.07 │ 69,184.… │ 65,675.17 │ 59,826.… │
│    First │          │          │           │          │           │          │
│    Token │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│  Time To │   509.14 │    30.05 │  1,011.39 │ 1,009.38 │    991.29 │   961.15 │
│   Second │          │          │           │          │           │          │
│    Token │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│  Request │ 87,971.… │ 32,334.… │ 134,682.… │ 134,072… │ 128,585.… │ 119,439… │
│  Latency │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│    Inter │    53.25 │    31.89 │     65.24 │    65.02 │     63.06 │    59.79 │
│    Token │          │          │           │          │           │          │
│  Latency │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│   Output │    20.30 │    15.33 │     31.36 │    30.94 │     27.13 │    20.79 │
│    Token │          │          │           │          │           │          │
│ Through… │          │          │           │          │           │          │
│ Per User │          │          │           │          │           │          │
│ (tokens… │          │          │           │          │           │          │
│   Output │   998.75 │   998.00 │    999.00 │   999.00 │    999.00 │   999.00 │
│ Sequence │          │          │           │          │           │          │
│   Length │          │          │           │          │           │          │
│ (tokens) │          │          │           │          │           │          │
│    Input │ 10,101.… │ 10,101.… │ 10,101.00 │ 10,101.… │ 10,101.00 │ 10,101.… │
│ Sequence │          │          │           │          │           │          │
│   Length │          │          │           │          │           │          │
│ (tokens) │          │          │           │          │           │          │
│   Output │    11.35 │      N/A │       N/A │      N/A │       N/A │      N/A │
│    Token │          │          │           │          │           │          │
│ Through… │          │          │           │          │           │          │
│ (tokens… │          │          │           │          │           │          │
│  Request │     0.01 │      N/A │       N/A │      N/A │       N/A │      N/A │
│ Through… │          │          │           │          │           │          │
│     (per │          │          │           │          │           │          │
│     sec) │          │          │           │          │           │          │
│  Request │     4.00 │      N/A │       N/A │      N/A │       N/A │      N/A │
│    Count │          │          │           │          │           │          │
│  (count) │          │          │           │          │           │          │
└──────────┴──────────┴──────────┴───────────┴──────────┴───────────┴──────────┘
[2025-11-01 15:01:52] INFO     Generating                    json_exporter.py:64
                               /tmp/simple_decode_test_1/_ho                    
                               me_bedicloud_models_deepseek-                    
                               ai_DeepSeek-R1-Distill-Llama-                    
                               70B-openai-chat-concurrency1/                    
                               profile_export_genai_perf.jso                    
                               n                                                
[2025-11-01 15:01:52] INFO     Generating                     csv_exporter.py:75
                               /tmp/simple_decode_test_1/_hom                   
                               e_bedicloud_models_deepseek-ai                   
                               _DeepSeek-R1-Distill-Llama-70B                   
                               -openai-chat-concurrency1/prof                   
                               ile_export_genai_perf.csv                        

----------------------------------------

================================================================================
================================================================================
DECODE TEST RESULTS - Concurrency: 10
Timestamp: 2025-11-01 15:06:00
Model: /home/bedicloud/models/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
Service URL: http://127.0.0.1:8003
Input Length: 10000, Output Length: 1000
Status: SUCCESS
================================================================================

GENAI-PERF OUTPUT:
----------------------------------------
[2025-11-01 15:01:58] INFO     Detected passthrough args: ['-vv',  parser.py:865
                               '--max-threads=300']                             
[2025-11-01 15:01:58] INFO     Profiling these models:       create_config.py:58
                               /home/bedicloud/models/deepse                    
                               ek-ai/DeepSeek-R1-Distill-Lla                    
                               ma-70B                                           
[2025-11-01 15:01:58] INFO     Model name            perf_analyzer_config.py:157
                               '/home/bedicloud/mode                            
                               ls/deepseek-ai/DeepSe                            
                               ek-R1-Distill-Llama-7                            
                               0B' cannot be used to                            
                               create artifact                                  
                               directory. Instead,                              
                               '_home_bedicloud_mode                            
                               ls_deepseek-ai_DeepSe                            
                               ek-R1-Distill-Llama-7                            
                               0B' will be used.                                
[2025-11-01 15:01:58] INFO     Creating tokenizer for:         subcommand.py:190
                               /home/bedicloud/models/deepseek                  
                               -ai/DeepSeek-R1-Distill-Llama-7                  
                               0B                                               
[2025-11-01 15:02:02] INFO     Running Perf Analyzer :          subcommand.py:98
                               'perf_analyzer -m                                
                               /home/bedicloud/models/deepseek-                 
                               ai/DeepSeek-R1-Distill-Llama-70B                 
                                --async --stability-percentage                  
                               999 --request-count 40 -i http                   
                               -u http://127.0.0.1:8003                         
                               --concurrency-range 10                           
                               --service-kind openai --endpoint                 
                               v1/chat/completions -vv                          
                               --max-threads=300 --input-data                   
                               /tmp/simple_decode_test_10/_home                 
                               _bedicloud_models_deepseek-ai_De                 
                               epSeek-R1-Distill-Llama-70B-open                 
                               ai-chat-concurrency10/inputs.jso                 
                               n --profile-export-file                          
                               /tmp/simple_decode_test_10/_home                 
                               _bedicloud_models_deepseek-ai_De                 
                               epSeek-R1-Distill-Llama-70B-open                 
                               ai-chat-concurrency10/profile_ex                 
                               port.json'                                       
[2025-11-01 15:05:53] INFO     Loading response data   profile_data_parser.py:66
                               from                                             
                               '/tmp/simple_decode_tes                          
                               t_10/_home_bedicloud_mo                          
                               dels_deepseek-ai_DeepSe                          
                               ek-R1-Distill-Llama-70B                          
                               -openai-chat-concurrenc                          
                               y10/profile_export.json                          
                               '                                                
[2025-11-01 15:05:53] INFO     Parsing total 40   llm_profile_data_parser.py:124
                               requests.                                        
                        NVIDIA GenAI-Perf | LLM Metrics                         
┏━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┓
┃ Statist… ┃      avg ┃      min ┃       max ┃      p99 ┃       p90 ┃      p75 ┃
┡━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━┩
│  Time To │ 14,715.… │   471.26 │ 40,715.04 │ 40,462.… │ 38,749.78 │ 23,331.… │
│    First │          │          │           │          │           │          │
│    Token │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│  Time To │ 3,477.63 │    18.43 │ 10,852.58 │ 10,852.… │  9,205.18 │ 7,866.03 │
│   Second │          │          │           │          │           │          │
│    Token │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│  Request │ 56,618.… │ 18,679.… │ 100,327.… │ 100,327… │ 100,326.… │ 85,732.… │
│  Latency │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│    Inter │    42.25 │    18.24 │     66.50 │    65.45 │     61.59 │    59.55 │
│    Token │          │          │           │          │           │          │
│  Latency │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│   Output │    29.36 │    15.04 │     54.82 │    54.31 │     50.65 │    40.03 │
│    Token │          │          │           │          │           │          │
│ Through… │          │          │           │          │           │          │
│ Per User │          │          │           │          │           │          │
│ (tokens… │          │          │           │          │           │          │
│   Output │   991.30 │   690.00 │  1,000.00 │   999.61 │    999.00 │   999.00 │
│ Sequence │          │          │           │          │           │          │
│   Length │          │          │           │          │           │          │
│ (tokens) │          │          │           │          │           │          │
│    Input │ 10,100.… │ 10,100.… │ 10,101.00 │ 10,101.… │ 10,101.00 │ 10,101.… │
│ Sequence │          │          │           │          │           │          │
│   Length │          │          │           │          │           │          │
│ (tokens) │          │          │           │          │           │          │
│   Output │   172.75 │      N/A │       N/A │      N/A │       N/A │      N/A │
│    Token │          │          │           │          │           │          │
│ Through… │          │          │           │          │           │          │
│ (tokens… │          │          │           │          │           │          │
│  Request │     0.17 │      N/A │       N/A │      N/A │       N/A │      N/A │
│ Through… │          │          │           │          │           │          │
│     (per │          │          │           │          │           │          │
│     sec) │          │          │           │          │           │          │
│  Request │    40.00 │      N/A │       N/A │      N/A │       N/A │      N/A │
│    Count │          │          │           │          │           │          │
│  (count) │          │          │           │          │           │          │
└──────────┴──────────┴──────────┴───────────┴──────────┴───────────┴──────────┘
[2025-11-01 15:06:00] INFO     Generating                    json_exporter.py:64
                               /tmp/simple_decode_test_10/_h                    
                               ome_bedicloud_models_deepseek                    
                               -ai_DeepSeek-R1-Distill-Llama                    
                               -70B-openai-chat-concurrency1                    
                               0/profile_export_genai_perf.j                    
                               son                                              
[2025-11-01 15:06:00] INFO     Generating                     csv_exporter.py:75
                               /tmp/simple_decode_test_10/_ho                   
                               me_bedicloud_models_deepseek-a                   
                               i_DeepSeek-R1-Distill-Llama-70                   
                               B-openai-chat-concurrency10/pr                   
                               ofile_export_genai_perf.csv                      

----------------------------------------

================================================================================
================================================================================
DECODE TEST RESULTS - Concurrency: 50
Timestamp: 2025-11-01 15:13:32
Model: /home/bedicloud/models/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
Service URL: http://127.0.0.1:8003
Input Length: 10000, Output Length: 1000
Status: SUCCESS
================================================================================

GENAI-PERF OUTPUT:
----------------------------------------
[2025-11-01 15:06:06] INFO     Detected passthrough args: ['-vv',  parser.py:865
                               '--max-threads=300']                             
[2025-11-01 15:06:06] INFO     Profiling these models:       create_config.py:58
                               /home/bedicloud/models/deepse                    
                               ek-ai/DeepSeek-R1-Distill-Lla                    
                               ma-70B                                           
[2025-11-01 15:06:06] INFO     Model name            perf_analyzer_config.py:157
                               '/home/bedicloud/mode                            
                               ls/deepseek-ai/DeepSe                            
                               ek-R1-Distill-Llama-7                            
                               0B' cannot be used to                            
                               create artifact                                  
                               directory. Instead,                              
                               '_home_bedicloud_mode                            
                               ls_deepseek-ai_DeepSe                            
                               ek-R1-Distill-Llama-7                            
                               0B' will be used.                                
[2025-11-01 15:06:06] INFO     Creating tokenizer for:         subcommand.py:190
                               /home/bedicloud/models/deepseek                  
                               -ai/DeepSeek-R1-Distill-Llama-7                  
                               0B                                               
[2025-11-01 15:06:10] INFO     Running Perf Analyzer :          subcommand.py:98
                               'perf_analyzer -m                                
                               /home/bedicloud/models/deepseek-                 
                               ai/DeepSeek-R1-Distill-Llama-70B                 
                                --async --stability-percentage                  
                               999 --request-count 200 -i http                  
                               -u http://127.0.0.1:8003                         
                               --concurrency-range 50                           
                               --service-kind openai --endpoint                 
                               v1/chat/completions -vv                          
                               --max-threads=300 --input-data                   
                               /tmp/simple_decode_test_50/_home                 
                               _bedicloud_models_deepseek-ai_De                 
                               epSeek-R1-Distill-Llama-70B-open                 
                               ai-chat-concurrency50/inputs.jso                 
                               n --profile-export-file                          
                               /tmp/simple_decode_test_50/_home                 
                               _bedicloud_models_deepseek-ai_De                 
                               epSeek-R1-Distill-Llama-70B-open                 
                               ai-chat-concurrency50/profile_ex                 
                               port.json'                                       
[2025-11-01 15:13:16] INFO     Loading response data   profile_data_parser.py:66
                               from                                             
                               '/tmp/simple_decode_tes                          
                               t_50/_home_bedicloud_mo                          
                               dels_deepseek-ai_DeepSe                          
                               ek-R1-Distill-Llama-70B                          
                               -openai-chat-concurrenc                          
                               y50/profile_export.json                          
                               '                                                
[2025-11-01 15:13:18] INFO     Parsing total 200  llm_profile_data_parser.py:124
                               requests.                                        
                        NVIDIA GenAI-Perf | LLM Metrics                         
┏━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┓
┃ Statist… ┃      avg ┃      min ┃       max ┃      p99 ┃       p90 ┃      p75 ┃
┡━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━┩
│  Time To │ 38,531.… │   999.57 │ 74,233.16 │ 73,588.… │ 58,042.31 │ 51,612.… │
│    First │          │          │           │          │           │          │
│    Token │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│  Time To │ 6,395.67 │    35.13 │ 20,984.18 │ 19,699.… │ 16,409.33 │ 10,742.… │
│   Second │          │          │           │          │           │          │
│    Token │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│  Request │ 98,300.… │ 57,612.… │ 180,352.… │ 136,978… │ 113,608.… │ 111,772… │
│  Latency │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│    Inter │    60.12 │    36.78 │    107.52 │    72.12 │     65.22 │    63.31 │
│    Token │          │          │           │          │           │          │
│  Latency │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│   Output │    16.78 │     9.30 │     27.19 │    19.54 │     18.42 │    17.77 │
│    Token │          │          │           │          │           │          │
│ Through… │          │          │           │          │           │          │
│ Per User │          │          │           │          │           │          │
│ (tokens… │          │          │           │          │           │          │
│   Output │   994.48 │   463.00 │  1,000.00 │   999.01 │    999.00 │   999.00 │
│ Sequence │          │          │           │          │           │          │
│   Length │          │          │           │          │           │          │
│ (tokens) │          │          │           │          │           │          │
│    Input │ 10,100.… │ 10,100.… │ 10,102.00 │ 10,102.… │ 10,101.00 │ 10,101.… │
│ Sequence │          │          │           │          │           │          │
│   Length │          │          │           │          │           │          │
│ (tokens) │          │          │           │          │           │          │
│   Output │   467.22 │      N/A │       N/A │      N/A │       N/A │      N/A │
│    Token │          │          │           │          │           │          │
│ Through… │          │          │           │          │           │          │
│ (tokens… │          │          │           │          │           │          │
│  Request │     0.47 │      N/A │       N/A │      N/A │       N/A │      N/A │
│ Through… │          │          │           │          │           │          │
│     (per │          │          │           │          │           │          │
│     sec) │          │          │           │          │           │          │
│  Request │   200.00 │      N/A │       N/A │      N/A │       N/A │      N/A │
│    Count │          │          │           │          │           │          │
│  (count) │          │          │           │          │           │          │
└──────────┴──────────┴──────────┴───────────┴──────────┴───────────┴──────────┘
[2025-11-01 15:13:31] INFO     Generating                    json_exporter.py:64
                               /tmp/simple_decode_test_50/_h                    
                               ome_bedicloud_models_deepseek                    
                               -ai_DeepSeek-R1-Distill-Llama                    
                               -70B-openai-chat-concurrency5                    
                               0/profile_export_genai_perf.j                    
                               son                                              
[2025-11-01 15:13:31] INFO     Generating                     csv_exporter.py:75
                               /tmp/simple_decode_test_50/_ho                   
                               me_bedicloud_models_deepseek-a                   
                               i_DeepSeek-R1-Distill-Llama-70                   
                               B-openai-chat-concurrency50/pr                   
                               ofile_export_genai_perf.csv                      

----------------------------------------

================================================================================
================================================================================
DECODE TEST RESULTS - Concurrency: 100
Timestamp: 2025-11-01 15:25:49
Model: /home/bedicloud/models/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
Service URL: http://127.0.0.1:8003
Input Length: 10000, Output Length: 1000
Status: SUCCESS
================================================================================

GENAI-PERF OUTPUT:
----------------------------------------
[2025-11-01 15:13:38] INFO     Detected passthrough args: ['-vv',  parser.py:865
                               '--max-threads=300']                             
[2025-11-01 15:13:38] INFO     Profiling these models:       create_config.py:58
                               /home/bedicloud/models/deepse                    
                               ek-ai/DeepSeek-R1-Distill-Lla                    
                               ma-70B                                           
[2025-11-01 15:13:38] INFO     Model name            perf_analyzer_config.py:157
                               '/home/bedicloud/mode                            
                               ls/deepseek-ai/DeepSe                            
                               ek-R1-Distill-Llama-7                            
                               0B' cannot be used to                            
                               create artifact                                  
                               directory. Instead,                              
                               '_home_bedicloud_mode                            
                               ls_deepseek-ai_DeepSe                            
                               ek-R1-Distill-Llama-7                            
                               0B' will be used.                                
[2025-11-01 15:13:38] INFO     Creating tokenizer for:         subcommand.py:190
                               /home/bedicloud/models/deepseek                  
                               -ai/DeepSeek-R1-Distill-Llama-7                  
                               0B                                               
[2025-11-01 15:13:42] INFO     Running Perf Analyzer :          subcommand.py:98
                               'perf_analyzer -m                                
                               /home/bedicloud/models/deepseek-                 
                               ai/DeepSeek-R1-Distill-Llama-70B                 
                                --async --stability-percentage                  
                               999 --request-count 400 -i http                  
                               -u http://127.0.0.1:8003                         
                               --concurrency-range 100                          
                               --service-kind openai --endpoint                 
                               v1/chat/completions -vv                          
                               --max-threads=300 --input-data                   
                               /tmp/simple_decode_test_100/_hom                 
                               e_bedicloud_models_deepseek-ai_D                 
                               eepSeek-R1-Distill-Llama-70B-ope                 
                               nai-chat-concurrency100/inputs.j                 
                               son --profile-export-file                        
                               /tmp/simple_decode_test_100/_hom                 
                               e_bedicloud_models_deepseek-ai_D                 
                               eepSeek-R1-Distill-Llama-70B-ope                 
                               nai-chat-concurrency100/profile_                 
                               export.json'                                     
[2025-11-01 15:25:25] INFO     Loading response data   profile_data_parser.py:66
                               from                                             
                               '/tmp/simple_decode_tes                          
                               t_100/_home_bedicloud_m                          
                               odels_deepseek-ai_DeepS                          
                               eek-R1-Distill-Llama-70                          
                               B-openai-chat-concurren                          
                               cy100/profile_export.js                          
                               on'                                              
[2025-11-01 15:25:28] INFO     Parsing total 400  llm_profile_data_parser.py:124
                               requests.                                        
                        NVIDIA GenAI-Perf | LLM Metrics                         
┏━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┓
┃ Statist… ┃      avg ┃      min ┃       max ┃      p99 ┃       p90 ┃      p75 ┃
┡━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━┩
│  Time To │ 95,349.… │    68.77 │ 170,326.… │ 144,796… │ 125,450.… │ 118,636… │
│    First │          │          │           │          │           │          │
│    Token │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│  Time To │ 6,789.67 │    27.68 │ 28,403.12 │ 26,485.… │ 16,704.33 │ 9,431.94 │
│   Second │          │          │           │          │           │          │
│    Token │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│  Request │ 152,983… │ 19,053.… │ 337,371.… │ 317,783… │ 184,485.… │ 173,642… │
│  Latency │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│    Inter │    58.12 │    19.02 │    203.05 │   175.01 │     65.06 │    60.67 │
│    Token │          │          │           │          │           │          │
│  Latency │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│   Output │    18.65 │     4.92 │     52.57 │    29.86 │     24.44 │    19.84 │
│    Token │          │          │           │          │           │          │
│ Through… │          │          │           │          │           │          │
│ Per User │          │          │           │          │           │          │
│ (tokens… │          │          │           │          │           │          │
│   Output │   996.49 │   350.00 │  1,002.00 │ 1,000.01 │    999.00 │   999.00 │
│ Sequence │          │          │           │          │           │          │
│   Length │          │          │           │          │           │          │
│ (tokens) │          │          │           │          │           │          │
│    Input │ 10,100.… │ 10,100.… │ 10,102.00 │ 10,102.… │ 10,101.00 │ 10,101.… │
│ Sequence │          │          │           │          │           │          │
│   Length │          │          │           │          │           │          │
│ (tokens) │          │          │           │          │           │          │
│   Output │   568.07 │      N/A │       N/A │      N/A │       N/A │      N/A │
│    Token │          │          │           │          │           │          │
│ Through… │          │          │           │          │           │          │
│ (tokens… │          │          │           │          │           │          │
│  Request │     0.57 │      N/A │       N/A │      N/A │       N/A │      N/A │
│ Through… │          │          │           │          │           │          │
│     (per │          │          │           │          │           │          │
│     sec) │          │          │           │          │           │          │
│  Request │   400.00 │      N/A │       N/A │      N/A │       N/A │      N/A │
│    Count │          │          │           │          │           │          │
│  (count) │          │          │           │          │           │          │
└──────────┴──────────┴──────────┴───────────┴──────────┴───────────┴──────────┘
[2025-11-01 15:25:48] INFO     Generating                    json_exporter.py:64
                               /tmp/simple_decode_test_100/_                    
                               home_bedicloud_models_deepsee                    
                               k-ai_DeepSeek-R1-Distill-Llam                    
                               a-70B-openai-chat-concurrency                    
                               100/profile_export_genai_perf                    
                               .json                                            
[2025-11-01 15:25:48] INFO     Generating                     csv_exporter.py:75
                               /tmp/simple_decode_test_100/_h                   
                               ome_bedicloud_models_deepseek-                   
                               ai_DeepSeek-R1-Distill-Llama-7                   
                               0B-openai-chat-concurrency100/                   
                               profile_export_genai_perf.csv                    

----------------------------------------

================================================================================
================================================================================
DECODE TEST RESULTS - Concurrency: 150
Timestamp: 2025-11-01 15:42:56
Model: /home/bedicloud/models/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
Service URL: http://127.0.0.1:8003
Input Length: 10000, Output Length: 1000
Status: SUCCESS
================================================================================

GENAI-PERF OUTPUT:
----------------------------------------
[2025-11-01 15:25:54] INFO     Detected passthrough args: ['-vv',  parser.py:865
                               '--max-threads=300']                             
[2025-11-01 15:25:54] INFO     Profiling these models:       create_config.py:58
                               /home/bedicloud/models/deepse                    
                               ek-ai/DeepSeek-R1-Distill-Lla                    
                               ma-70B                                           
[2025-11-01 15:25:54] INFO     Model name            perf_analyzer_config.py:157
                               '/home/bedicloud/mode                            
                               ls/deepseek-ai/DeepSe                            
                               ek-R1-Distill-Llama-7                            
                               0B' cannot be used to                            
                               create artifact                                  
                               directory. Instead,                              
                               '_home_bedicloud_mode                            
                               ls_deepseek-ai_DeepSe                            
                               ek-R1-Distill-Llama-7                            
                               0B' will be used.                                
[2025-11-01 15:25:54] INFO     Creating tokenizer for:         subcommand.py:190
                               /home/bedicloud/models/deepseek                  
                               -ai/DeepSeek-R1-Distill-Llama-7                  
                               0B                                               
[2025-11-01 15:25:58] INFO     Running Perf Analyzer :          subcommand.py:98
                               'perf_analyzer -m                                
                               /home/bedicloud/models/deepseek-                 
                               ai/DeepSeek-R1-Distill-Llama-70B                 
                                --async --stability-percentage                  
                               999 --request-count 600 -i http                  
                               -u http://127.0.0.1:8003                         
                               --concurrency-range 150                          
                               --service-kind openai --endpoint                 
                               v1/chat/completions -vv                          
                               --max-threads=300 --input-data                   
                               /tmp/simple_decode_test_150/_hom                 
                               e_bedicloud_models_deepseek-ai_D                 
                               eepSeek-R1-Distill-Llama-70B-ope                 
                               nai-chat-concurrency150/inputs.j                 
                               son --profile-export-file                        
                               /tmp/simple_decode_test_150/_hom                 
                               e_bedicloud_models_deepseek-ai_D                 
                               eepSeek-R1-Distill-Llama-70B-ope                 
                               nai-chat-concurrency150/profile_                 
                               export.json'                                     
[2025-11-01 15:42:25] INFO     Loading response data   profile_data_parser.py:66
                               from                                             
                               '/tmp/simple_decode_tes                          
                               t_150/_home_bedicloud_m                          
                               odels_deepseek-ai_DeepS                          
                               eek-R1-Distill-Llama-70                          
                               B-openai-chat-concurren                          
                               cy150/profile_export.js                          
                               on'                                              
[2025-11-01 15:42:28] INFO     Parsing total 600  llm_profile_data_parser.py:124
                               requests.                                        
                        NVIDIA GenAI-Perf | LLM Metrics                         
┏━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┓
┃ Statist… ┃      avg ┃      min ┃      max ┃       p99 ┃      p90 ┃       p75 ┃
┡━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━┩
│  Time To │ 166,231… │ 54,816.… │ 217,633… │ 212,099.… │ 195,710… │ 185,568.… │
│    First │          │          │          │           │          │           │
│    Token │          │          │          │           │          │           │
│     (ms) │          │          │          │           │          │           │
│  Time To │ 3,266.86 │    35.07 │ 16,266.… │ 15,379.05 │ 8,515.06 │  4,982.51 │
│   Second │          │          │          │           │          │           │
│    Token │          │          │          │           │          │           │
│     (ms) │          │          │          │           │          │           │
│  Request │ 227,574… │ 100,166… │ 417,357… │ 390,321.… │ 259,762… │ 244,736.… │
│  Latency │          │          │          │           │          │           │
│     (ms) │          │          │          │           │          │           │
│    Inter │    61.96 │    40.96 │   251.16 │    228.53 │    64.12 │     61.50 │
│    Token │          │          │          │           │          │           │
│  Latency │          │          │          │           │          │           │
│     (ms) │          │          │          │           │          │           │
│   Output │    17.07 │     3.98 │    24.42 │     23.02 │    19.49 │     18.15 │
│    Token │          │          │          │           │          │           │
│ Through… │          │          │          │           │          │           │
│ Per User │          │          │          │           │          │           │
│ (tokens… │          │          │          │           │          │           │
│   Output │   992.01 │   356.00 │ 1,001.00 │  1,000.00 │   999.00 │    999.00 │
│ Sequence │          │          │          │           │          │           │
│   Length │          │          │          │           │          │           │
│ (tokens) │          │          │          │           │          │           │
│    Input │ 10,100.… │ 10,100.… │ 10,102.… │ 10,102.00 │ 10,101.… │ 10,101.00 │
│ Sequence │          │          │          │           │          │           │
│   Length │          │          │          │           │          │           │
│ (tokens) │          │          │          │           │          │           │
│   Output │   604.78 │      N/A │      N/A │       N/A │      N/A │       N/A │
│    Token │          │          │          │           │          │           │
│ Through… │          │          │          │           │          │           │
│ (tokens… │          │          │          │           │          │           │
│  Request │     0.61 │      N/A │      N/A │       N/A │      N/A │       N/A │
│ Through… │          │          │          │           │          │           │
│     (per │          │          │          │           │          │           │
│     sec) │          │          │          │           │          │           │
│  Request │   600.00 │      N/A │      N/A │       N/A │      N/A │       N/A │
│    Count │          │          │          │           │          │           │
│  (count) │          │          │          │           │          │           │
└──────────┴──────────┴──────────┴──────────┴───────────┴──────────┴───────────┘
[2025-11-01 15:42:55] INFO     Generating                    json_exporter.py:64
                               /tmp/simple_decode_test_150/_                    
                               home_bedicloud_models_deepsee                    
                               k-ai_DeepSeek-R1-Distill-Llam                    
                               a-70B-openai-chat-concurrency                    
                               150/profile_export_genai_perf                    
                               .json                                            
[2025-11-01 15:42:55] INFO     Generating                     csv_exporter.py:75
                               /tmp/simple_decode_test_150/_h                   
                               ome_bedicloud_models_deepseek-                   
                               ai_DeepSeek-R1-Distill-Llama-7                   
                               0B-openai-chat-concurrency150/                   
                               profile_export_genai_perf.csv                    

----------------------------------------

================================================================================
================================================================================
DECODE TEST RESULTS - Concurrency: 200
Timestamp: 2025-11-01 15:59:17
Model: /home/bedicloud/models/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
Service URL: http://127.0.0.1:8003
Input Length: 10000, Output Length: 1000
Status: SUCCESS
================================================================================

GENAI-PERF OUTPUT:
----------------------------------------
[2025-11-01 15:43:01] INFO     Detected passthrough args: ['-vv',  parser.py:865
                               '--max-threads=300']                             
[2025-11-01 15:43:01] INFO     Profiling these models:       create_config.py:58
                               /home/bedicloud/models/deepse                    
                               ek-ai/DeepSeek-R1-Distill-Lla                    
                               ma-70B                                           
[2025-11-01 15:43:01] INFO     Model name            perf_analyzer_config.py:157
                               '/home/bedicloud/mode                            
                               ls/deepseek-ai/DeepSe                            
                               ek-R1-Distill-Llama-7                            
                               0B' cannot be used to                            
                               create artifact                                  
                               directory. Instead,                              
                               '_home_bedicloud_mode                            
                               ls_deepseek-ai_DeepSe                            
                               ek-R1-Distill-Llama-7                            
                               0B' will be used.                                
[2025-11-01 15:43:01] INFO     Creating tokenizer for:         subcommand.py:190
                               /home/bedicloud/models/deepseek                  
                               -ai/DeepSeek-R1-Distill-Llama-7                  
                               0B                                               
[2025-11-01 15:43:05] INFO     Running Perf Analyzer :          subcommand.py:98
                               'perf_analyzer -m                                
                               /home/bedicloud/models/deepseek-                 
                               ai/DeepSeek-R1-Distill-Llama-70B                 
                                --async --stability-percentage                  
                               999 --request-count 800 -i http                  
                               -u http://127.0.0.1:8003                         
                               --concurrency-range 200                          
                               --service-kind openai --endpoint                 
                               v1/chat/completions -vv                          
                               --max-threads=300 --input-data                   
                               /tmp/simple_decode_test_200/_hom                 
                               e_bedicloud_models_deepseek-ai_D                 
                               eepSeek-R1-Distill-Llama-70B-ope                 
                               nai-chat-concurrency200/inputs.j                 
                               son --profile-export-file                        
                               /tmp/simple_decode_test_200/_hom                 
                               e_bedicloud_models_deepseek-ai_D                 
                               eepSeek-R1-Distill-Llama-70B-ope                 
                               nai-chat-concurrency200/profile_                 
                               export.json'                                     
[2025-11-01 15:58:40] INFO     Loading response data   profile_data_parser.py:66
                               from                                             
                               '/tmp/simple_decode_tes                          
                               t_200/_home_bedicloud_m                          
                               odels_deepseek-ai_DeepS                          
                               eek-R1-Distill-Llama-70                          
                               B-openai-chat-concurren                          
                               cy200/profile_export.js                          
                               on'                                              
[2025-11-01 15:58:46] INFO     Parsing total 800  llm_profile_data_parser.py:124
                               requests.                                        
                        NVIDIA GenAI-Perf | LLM Metrics                         
┏━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┓
┃ Statist… ┃      avg ┃      min ┃       max ┃      p99 ┃       p90 ┃      p75 ┃
┡━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━┩
│  Time To │ 164,547… │    60.45 │ 208,818.… │ 205,426… │ 196,298.… │ 190,109… │
│    First │          │          │           │          │           │          │
│    Token │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│  Time To │ 10,773.… │    18.49 │ 27,675.96 │ 26,383.… │ 21,961.15 │ 17,033.… │
│   Second │          │          │           │          │           │          │
│    Token │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│  Request │ 214,504… │ 16,427.… │ 381,663.… │ 340,549… │ 244,260.… │ 239,792… │
│  Latency │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│    Inter │    50.26 │    16.40 │    257.62 │   187.25 │     58.19 │    53.58 │
│    Token │          │          │           │          │           │          │
│  Latency │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│   Output │    21.84 │     3.88 │     60.97 │    30.64 │     27.91 │    25.32 │
│    Token │          │          │           │          │           │          │
│ Through… │          │          │           │          │           │          │
│ Per User │          │          │           │          │           │          │
│ (tokens… │          │          │           │          │           │          │
│   Output │   995.20 │   521.00 │  1,005.00 │ 1,000.00 │    999.00 │   999.00 │
│ Sequence │          │          │           │          │           │          │
│   Length │          │          │           │          │           │          │
│ (tokens) │          │          │           │          │           │          │
│    Input │ 10,100.… │ 10,100.… │ 10,102.00 │ 10,102.… │ 10,101.00 │ 10,101.… │
│ Sequence │          │          │           │          │           │          │
│   Length │          │          │           │          │           │          │
│ (tokens) │          │          │           │          │           │          │
│   Output │   853.99 │      N/A │       N/A │      N/A │       N/A │      N/A │
│    Token │          │          │           │          │           │          │
│ Through… │          │          │           │          │           │          │
│ (tokens… │          │          │           │          │           │          │
│  Request │     0.86 │      N/A │       N/A │      N/A │       N/A │      N/A │
│ Through… │          │          │           │          │           │          │
│     (per │          │          │           │          │           │          │
│     sec) │          │          │           │          │           │          │
│  Request │   800.00 │      N/A │       N/A │      N/A │       N/A │      N/A │
│    Count │          │          │           │          │           │          │
│  (count) │          │          │           │          │           │          │
└──────────┴──────────┴──────────┴───────────┴──────────┴───────────┴──────────┘
[2025-11-01 15:59:16] INFO     Generating                    json_exporter.py:64
                               /tmp/simple_decode_test_200/_                    
                               home_bedicloud_models_deepsee                    
                               k-ai_DeepSeek-R1-Distill-Llam                    
                               a-70B-openai-chat-concurrency                    
                               200/profile_export_genai_perf                    
                               .json                                            
[2025-11-01 15:59:16] INFO     Generating                     csv_exporter.py:75
                               /tmp/simple_decode_test_200/_h                   
                               ome_bedicloud_models_deepseek-                   
                               ai_DeepSeek-R1-Distill-Llama-7                   
                               0B-openai-chat-concurrency200/                   
                               profile_export_genai_perf.csv                    

----------------------------------------

================================================================================
================================================================================
DECODE TEST RESULTS - Concurrency: 250
Timestamp: 2025-11-01 16:21:03
Model: /home/bedicloud/models/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
Service URL: http://127.0.0.1:8003
Input Length: 10000, Output Length: 1000
Status: SUCCESS
================================================================================

GENAI-PERF OUTPUT:
----------------------------------------
[2025-11-01 15:59:23] INFO     Detected passthrough args: ['-vv',  parser.py:865
                               '--max-threads=300']                             
[2025-11-01 15:59:23] INFO     Profiling these models:       create_config.py:58
                               /home/bedicloud/models/deepse                    
                               ek-ai/DeepSeek-R1-Distill-Lla                    
                               ma-70B                                           
[2025-11-01 15:59:23] INFO     Model name            perf_analyzer_config.py:157
                               '/home/bedicloud/mode                            
                               ls/deepseek-ai/DeepSe                            
                               ek-R1-Distill-Llama-7                            
                               0B' cannot be used to                            
                               create artifact                                  
                               directory. Instead,                              
                               '_home_bedicloud_mode                            
                               ls_deepseek-ai_DeepSe                            
                               ek-R1-Distill-Llama-7                            
                               0B' will be used.                                
[2025-11-01 15:59:23] INFO     Creating tokenizer for:         subcommand.py:190
                               /home/bedicloud/models/deepseek                  
                               -ai/DeepSeek-R1-Distill-Llama-7                  
                               0B                                               
[2025-11-01 15:59:26] INFO     Running Perf Analyzer :          subcommand.py:98
                               'perf_analyzer -m                                
                               /home/bedicloud/models/deepseek-                 
                               ai/DeepSeek-R1-Distill-Llama-70B                 
                                --async --stability-percentage                  
                               999 --request-count 1000 -i http                 
                               -u http://127.0.0.1:8003                         
                               --concurrency-range 250                          
                               --service-kind openai --endpoint                 
                               v1/chat/completions -vv                          
                               --max-threads=300 --input-data                   
                               /tmp/simple_decode_test_250/_hom                 
                               e_bedicloud_models_deepseek-ai_D                 
                               eepSeek-R1-Distill-Llama-70B-ope                 
                               nai-chat-concurrency250/inputs.j                 
                               son --profile-export-file                        
                               /tmp/simple_decode_test_250/_hom                 
                               e_bedicloud_models_deepseek-ai_D                 
                               eepSeek-R1-Distill-Llama-70B-ope                 
                               nai-chat-concurrency250/profile_                 
                               export.json'                                     
[2025-11-01 16:20:17] INFO     Loading response data   profile_data_parser.py:66
                               from                                             
                               '/tmp/simple_decode_tes                          
                               t_250/_home_bedicloud_m                          
                               odels_deepseek-ai_DeepS                          
                               eek-R1-Distill-Llama-70                          
                               B-openai-chat-concurren                          
                               cy250/profile_export.js                          
                               on'                                              
[2025-11-01 16:20:26] INFO     Parsing total 1000 llm_profile_data_parser.py:124
                               requests.                                        
                        NVIDIA GenAI-Perf | LLM Metrics                         
┏━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┓
┃ Statist… ┃      avg ┃      min ┃       max ┃      p99 ┃       p90 ┃      p75 ┃
┡━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━┩
│  Time To │ 221,612… │ 24,764.… │ 289,853.… │ 268,173… │ 256,370.… │ 249,526… │
│    First │          │          │           │          │           │          │
│    Token │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│  Time To │ 10,643.… │    34.84 │ 28,561.60 │ 27,220.… │ 22,178.15 │ 17,103.… │
│   Second │          │          │           │          │           │          │
│    Token │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│  Request │ 276,238… │ 62,588.… │ 542,603.… │ 481,592… │ 309,066.… │ 303,716… │
│  Latency │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│    Inter │    54.85 │    32.61 │    315.80 │   269.57 │     59.96 │    55.15 │
│    Token │          │          │           │          │           │          │
│  Latency │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│   Output │    20.86 │     3.17 │     30.66 │    29.98 │     26.97 │    24.04 │
│    Token │          │          │           │          │           │          │
│ Through… │          │          │           │          │           │          │
│ Per User │          │          │           │          │           │          │
│ (tokens… │          │          │           │          │           │          │
│   Output │   997.11 │   542.00 │  1,002.00 │ 1,000.00 │    999.00 │   999.00 │
│ Sequence │          │          │           │          │           │          │
│   Length │          │          │           │          │           │          │
│ (tokens) │          │          │           │          │           │          │
│    Input │ 10,100.… │ 10,100.… │ 10,102.00 │ 10,102.… │ 10,101.00 │ 10,101.… │
│ Sequence │          │          │           │          │           │          │
│   Length │          │          │           │          │           │          │
│ (tokens) │          │          │           │          │           │          │
│   Output │   798.98 │      N/A │       N/A │      N/A │       N/A │      N/A │
│    Token │          │          │           │          │           │          │
│ Through… │          │          │           │          │           │          │
│ (tokens… │          │          │           │          │           │          │
│  Request │     0.80 │      N/A │       N/A │      N/A │       N/A │      N/A │
│ Through… │          │          │           │          │           │          │
│     (per │          │          │           │          │           │          │
│     sec) │          │          │           │          │           │          │
│  Request │ 1,000.00 │      N/A │       N/A │      N/A │       N/A │      N/A │
│    Count │          │          │           │          │           │          │
│  (count) │          │          │           │          │           │          │
└──────────┴──────────┴──────────┴───────────┴──────────┴───────────┴──────────┘
[2025-11-01 16:21:03] INFO     Generating                    json_exporter.py:64
                               /tmp/simple_decode_test_250/_                    
                               home_bedicloud_models_deepsee                    
                               k-ai_DeepSeek-R1-Distill-Llam                    
                               a-70B-openai-chat-concurrency                    
                               250/profile_export_genai_perf                    
                               .json                                            
[2025-11-01 16:21:03] INFO     Generating                     csv_exporter.py:75
                               /tmp/simple_decode_test_250/_h                   
                               ome_bedicloud_models_deepseek-                   
                               ai_DeepSeek-R1-Distill-Llama-7                   
                               0B-openai-chat-concurrency250/                   
                               profile_export_genai_perf.csv                    

----------------------------------------

================================================================================
================================================================================
DECODE TEST RESULTS - Concurrency: 300
Timestamp: 2025-11-01 16:49:19
Model: /home/bedicloud/models/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
Service URL: http://127.0.0.1:8003
Input Length: 10000, Output Length: 1000
Status: SUCCESS
================================================================================

GENAI-PERF OUTPUT:
----------------------------------------
[2025-11-01 16:21:09] INFO     Detected passthrough args: ['-vv',  parser.py:865
                               '--max-threads=300']                             
[2025-11-01 16:21:09] INFO     Profiling these models:       create_config.py:58
                               /home/bedicloud/models/deepse                    
                               ek-ai/DeepSeek-R1-Distill-Lla                    
                               ma-70B                                           
[2025-11-01 16:21:09] INFO     Model name            perf_analyzer_config.py:157
                               '/home/bedicloud/mode                            
                               ls/deepseek-ai/DeepSe                            
                               ek-R1-Distill-Llama-7                            
                               0B' cannot be used to                            
                               create artifact                                  
                               directory. Instead,                              
                               '_home_bedicloud_mode                            
                               ls_deepseek-ai_DeepSe                            
                               ek-R1-Distill-Llama-7                            
                               0B' will be used.                                
[2025-11-01 16:21:09] INFO     Creating tokenizer for:         subcommand.py:190
                               /home/bedicloud/models/deepseek                  
                               -ai/DeepSeek-R1-Distill-Llama-7                  
                               0B                                               
[2025-11-01 16:21:13] INFO     Running Perf Analyzer :          subcommand.py:98
                               'perf_analyzer -m                                
                               /home/bedicloud/models/deepseek-                 
                               ai/DeepSeek-R1-Distill-Llama-70B                 
                                --async --stability-percentage                  
                               999 --request-count 1200 -i http                 
                               -u http://127.0.0.1:8003                         
                               --concurrency-range 300                          
                               --service-kind openai --endpoint                 
                               v1/chat/completions -vv                          
                               --max-threads=300 --input-data                   
                               /tmp/simple_decode_test_300/_hom                 
                               e_bedicloud_models_deepseek-ai_D                 
                               eepSeek-R1-Distill-Llama-70B-ope                 
                               nai-chat-concurrency300/inputs.j                 
                               son --profile-export-file                        
                               /tmp/simple_decode_test_300/_hom                 
                               e_bedicloud_models_deepseek-ai_D                 
                               eepSeek-R1-Distill-Llama-70B-ope                 
                               nai-chat-concurrency300/profile_                 
                               export.json'                                     
[2025-11-01 16:48:23] INFO     Loading response data   profile_data_parser.py:66
                               from                                             
                               '/tmp/simple_decode_tes                          
                               t_300/_home_bedicloud_m                          
                               odels_deepseek-ai_DeepS                          
                               eek-R1-Distill-Llama-70                          
                               B-openai-chat-concurren                          
                               cy300/profile_export.js                          
                               on'                                              
[2025-11-01 16:48:33] INFO     Parsing total 1200 llm_profile_data_parser.py:124
                               requests.                                        
                        NVIDIA GenAI-Perf | LLM Metrics                         
┏━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┓
┃ Statist… ┃      avg ┃      min ┃       max ┃      p99 ┃       p90 ┃      p75 ┃
┡━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━┩
│  Time To │ 265,546… │ 2,128.69 │ 376,560.… │ 373,957… │ 363,656.… │ 330,179… │
│    First │          │          │           │          │           │          │
│    Token │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│  Time To │ 8,222.59 │    34.03 │ 26,786.56 │ 22,723.… │ 18,125.41 │ 14,133.… │
│   Second │          │          │           │          │           │          │
│    Token │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│  Request │ 325,045… │ 38,369.… │ 775,670.… │ 661,394… │ 419,926.… │ 379,585… │
│  Latency │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│    Inter │    59.78 │    34.35 │    417.95 │   369.44 │     59.56 │    56.71 │
│    Token │          │          │           │          │           │          │
│  Latency │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│   Output │    19.87 │     2.39 │     29.12 │    27.84 │     25.16 │    22.62 │
│    Token │          │          │           │          │           │          │
│ Through… │          │          │           │          │           │          │
│ Per User │          │          │           │          │           │          │
│ (tokens… │          │          │           │          │           │          │
│   Output │   995.97 │   468.00 │  1,005.00 │ 1,000.00 │    999.00 │   999.00 │
│ Sequence │          │          │           │          │           │          │
│   Length │          │          │           │          │           │          │
│ (tokens) │          │          │           │          │           │          │
│    Input │ 10,100.… │ 10,100.… │ 10,102.00 │ 10,102.… │ 10,101.00 │ 10,101.… │
│ Sequence │          │          │           │          │           │          │
│   Length │          │          │           │          │           │          │
│ (tokens) │          │          │           │          │           │          │
│   Output │   734.84 │      N/A │       N/A │      N/A │       N/A │      N/A │
│    Token │          │          │           │          │           │          │
│ Through… │          │          │           │          │           │          │
│ (tokens… │          │          │           │          │           │          │
│  Request │     0.74 │      N/A │       N/A │      N/A │       N/A │      N/A │
│ Through… │          │          │           │          │           │          │
│     (per │          │          │           │          │           │          │
│     sec) │          │          │           │          │           │          │
│  Request │ 1,200.00 │      N/A │       N/A │      N/A │       N/A │      N/A │
│    Count │          │          │           │          │           │          │
│  (count) │          │          │           │          │           │          │
└──────────┴──────────┴──────────┴───────────┴──────────┴───────────┴──────────┘
[2025-11-01 16:49:18] INFO     Generating                    json_exporter.py:64
                               /tmp/simple_decode_test_300/_                    
                               home_bedicloud_models_deepsee                    
                               k-ai_DeepSeek-R1-Distill-Llam                    
                               a-70B-openai-chat-concurrency                    
                               300/profile_export_genai_perf                    
                               .json                                            
[2025-11-01 16:49:18] INFO     Generating                     csv_exporter.py:75
                               /tmp/simple_decode_test_300/_h                   
                               ome_bedicloud_models_deepseek-                   
                               ai_DeepSeek-R1-Distill-Llama-7                   
                               0B-openai-chat-concurrency300/                   
                               profile_export_genai_perf.csv                    

----------------------------------------

================================================================================
================================================================================
DECODE TEST RESULTS - Concurrency: 350
Timestamp: 2025-11-01 17:24:31
Model: /home/bedicloud/models/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
Service URL: http://127.0.0.1:8003
Input Length: 10000, Output Length: 1000
Status: SUCCESS
================================================================================

GENAI-PERF OUTPUT:
----------------------------------------
[2025-11-01 16:49:24] INFO     Detected passthrough args: ['-vv',  parser.py:865
                               '--max-threads=300']                             
[2025-11-01 16:49:24] INFO     Profiling these models:       create_config.py:58
                               /home/bedicloud/models/deepse                    
                               ek-ai/DeepSeek-R1-Distill-Lla                    
                               ma-70B                                           
[2025-11-01 16:49:24] INFO     Model name            perf_analyzer_config.py:157
                               '/home/bedicloud/mode                            
                               ls/deepseek-ai/DeepSe                            
                               ek-R1-Distill-Llama-7                            
                               0B' cannot be used to                            
                               create artifact                                  
                               directory. Instead,                              
                               '_home_bedicloud_mode                            
                               ls_deepseek-ai_DeepSe                            
                               ek-R1-Distill-Llama-7                            
                               0B' will be used.                                
[2025-11-01 16:49:24] INFO     Creating tokenizer for:         subcommand.py:190
                               /home/bedicloud/models/deepseek                  
                               -ai/DeepSeek-R1-Distill-Llama-7                  
                               0B                                               
[2025-11-01 16:49:28] INFO     Running Perf Analyzer :          subcommand.py:98
                               'perf_analyzer -m                                
                               /home/bedicloud/models/deepseek-                 
                               ai/DeepSeek-R1-Distill-Llama-70B                 
                                --async --stability-percentage                  
                               999 --request-count 1400 -i http                 
                               -u http://127.0.0.1:8003                         
                               --concurrency-range 350                          
                               --service-kind openai --endpoint                 
                               v1/chat/completions -vv                          
                               --max-threads=300 --input-data                   
                               /tmp/simple_decode_test_350/_hom                 
                               e_bedicloud_models_deepseek-ai_D                 
                               eepSeek-R1-Distill-Llama-70B-ope                 
                               nai-chat-concurrency350/inputs.j                 
                               son --profile-export-file                        
                               /tmp/simple_decode_test_350/_hom                 
                               e_bedicloud_models_deepseek-ai_D                 
                               eepSeek-R1-Distill-Llama-70B-ope                 
                               nai-chat-concurrency350/profile_                 
                               export.json'                                     
[2025-11-01 17:23:26] INFO     Loading response data   profile_data_parser.py:66
                               from                                             
                               '/tmp/simple_decode_tes                          
                               t_350/_home_bedicloud_m                          
                               odels_deepseek-ai_DeepS                          
                               eek-R1-Distill-Llama-70                          
                               B-openai-chat-concurren                          
                               cy350/profile_export.js                          
                               on'                                              
[2025-11-01 17:23:39] INFO     Parsing total 1400 llm_profile_data_parser.py:124
                               requests.                                        
                        NVIDIA GenAI-Perf | LLM Metrics                         
┏━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┓
┃ Statist… ┃      avg ┃      min ┃       max ┃      p99 ┃       p90 ┃      p75 ┃
┡━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━┩
│  Time To │ 352,844… │    56.95 │ 490,962.… │ 487,508… │ 448,235.… │ 433,000… │
│    First │          │          │           │          │           │          │
│    Token │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│  Time To │ 7,141.45 │    16.17 │ 27,669.43 │ 24,458.… │ 16,580.80 │ 11,263.… │
│   Second │          │          │           │          │           │          │
│    Token │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│  Request │ 412,654… │ 16,218.… │ 963,635.… │ 837,319… │ 504,201.… │ 488,247… │
│  Latency │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│    Inter │    60.06 │    16.19 │    534.06 │   470.26 │     59.53 │    56.13 │
│    Token │          │          │           │          │           │          │
│  Latency │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│   Output │    20.11 │     1.87 │     61.75 │    33.01 │     25.55 │    22.22 │
│    Token │          │          │           │          │           │          │
│ Through… │          │          │           │          │           │          │
│ Per User │          │          │           │          │           │          │
│ (tokens… │          │          │           │          │           │          │
│   Output │   996.72 │   386.00 │  1,002.00 │ 1,000.00 │    999.00 │   999.00 │
│ Sequence │          │          │           │          │           │          │
│   Length │          │          │           │          │           │          │
│ (tokens) │          │          │           │          │           │          │
│    Input │ 10,100.… │ 10,100.… │ 10,102.00 │ 10,102.… │ 10,101.00 │ 10,101.… │
│ Sequence │          │          │           │          │           │          │
│   Length │          │          │           │          │           │          │
│ (tokens) │          │          │           │          │           │          │
│   Output │   686.28 │      N/A │       N/A │      N/A │       N/A │      N/A │
│    Token │          │          │           │          │           │          │
│ Through… │          │          │           │          │           │          │
│ (tokens… │          │          │           │          │           │          │
│  Request │     0.69 │      N/A │       N/A │      N/A │       N/A │      N/A │
│ Through… │          │          │           │          │           │          │
│     (per │          │          │           │          │           │          │
│     sec) │          │          │           │          │           │          │
│  Request │ 1,400.00 │      N/A │       N/A │      N/A │       N/A │      N/A │
│    Count │          │          │           │          │           │          │
│  (count) │          │          │           │          │           │          │
└──────────┴──────────┴──────────┴───────────┴──────────┴───────────┴──────────┘
[2025-11-01 17:24:30] INFO     Generating                    json_exporter.py:64
                               /tmp/simple_decode_test_350/_                    
                               home_bedicloud_models_deepsee                    
                               k-ai_DeepSeek-R1-Distill-Llam                    
                               a-70B-openai-chat-concurrency                    
                               350/profile_export_genai_perf                    
                               .json                                            
[2025-11-01 17:24:30] INFO     Generating                     csv_exporter.py:75
                               /tmp/simple_decode_test_350/_h                   
                               ome_bedicloud_models_deepseek-                   
                               ai_DeepSeek-R1-Distill-Llama-7                   
                               0B-openai-chat-concurrency350/                   
                               profile_export_genai_perf.csv                    

----------------------------------------

================================================================================
================================================================================
DECODE TEST RESULTS - Concurrency: 400
Timestamp: 2025-11-01 18:06:03
Model: /home/bedicloud/models/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
Service URL: http://127.0.0.1:8003
Input Length: 10000, Output Length: 1000
Status: SUCCESS
================================================================================

GENAI-PERF OUTPUT:
----------------------------------------
[2025-11-01 17:24:36] INFO     Detected passthrough args: ['-vv',  parser.py:865
                               '--max-threads=300']                             
[2025-11-01 17:24:36] INFO     Profiling these models:       create_config.py:58
                               /home/bedicloud/models/deepse                    
                               ek-ai/DeepSeek-R1-Distill-Lla                    
                               ma-70B                                           
[2025-11-01 17:24:36] INFO     Model name            perf_analyzer_config.py:157
                               '/home/bedicloud/mode                            
                               ls/deepseek-ai/DeepSe                            
                               ek-R1-Distill-Llama-7                            
                               0B' cannot be used to                            
                               create artifact                                  
                               directory. Instead,                              
                               '_home_bedicloud_mode                            
                               ls_deepseek-ai_DeepSe                            
                               ek-R1-Distill-Llama-7                            
                               0B' will be used.                                
[2025-11-01 17:24:36] INFO     Creating tokenizer for:         subcommand.py:190
                               /home/bedicloud/models/deepseek                  
                               -ai/DeepSeek-R1-Distill-Llama-7                  
                               0B                                               
[2025-11-01 17:24:40] INFO     Running Perf Analyzer :          subcommand.py:98
                               'perf_analyzer -m                                
                               /home/bedicloud/models/deepseek-                 
                               ai/DeepSeek-R1-Distill-Llama-70B                 
                                --async --stability-percentage                  
                               999 --request-count 1600 -i http                 
                               -u http://127.0.0.1:8003                         
                               --concurrency-range 400                          
                               --service-kind openai --endpoint                 
                               v1/chat/completions -vv                          
                               --max-threads=300 --input-data                   
                               /tmp/simple_decode_test_400/_hom                 
                               e_bedicloud_models_deepseek-ai_D                 
                               eepSeek-R1-Distill-Llama-70B-ope                 
                               nai-chat-concurrency400/inputs.j                 
                               son --profile-export-file                        
                               /tmp/simple_decode_test_400/_hom                 
                               e_bedicloud_models_deepseek-ai_D                 
                               eepSeek-R1-Distill-Llama-70B-ope                 
                               nai-chat-concurrency400/profile_                 
                               export.json'                                     
[2025-11-01 18:04:53] INFO     Loading response data   profile_data_parser.py:66
                               from                                             
                               '/tmp/simple_decode_tes                          
                               t_400/_home_bedicloud_m                          
                               odels_deepseek-ai_DeepS                          
                               eek-R1-Distill-Llama-70                          
                               B-openai-chat-concurren                          
                               cy400/profile_export.js                          
                               on'                                              
[2025-11-01 18:05:05] INFO     Parsing total 1600 llm_profile_data_parser.py:124
                               requests.                                        
                        NVIDIA GenAI-Perf | LLM Metrics                         
┏━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┓
┃ Statist… ┃      avg ┃      min ┃       max ┃      p99 ┃       p90 ┃      p75 ┃
┡━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━┩
│  Time To │ 431,693… │   852.31 │ 570,278.… │ 564,496… │ 541,721.… │ 515,515… │
│    First │          │          │           │          │           │          │
│    Token │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│  Time To │ 8,422.54 │    16.94 │ 26,758.99 │ 23,877.… │ 18,934.68 │ 13,935.… │
│   Second │          │          │           │          │           │          │
│    Token │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│  Request │ 498,831… │ 17,580.… │ 1,092,70… │ 1,058,9… │ 602,087.… │ 570,386… │
│  Latency │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│    Inter │    67.59 │    16.76 │    753.13 │   556.74 │     61.06 │    56.64 │
│    Token │          │          │           │          │           │          │
│  Latency │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│   Output │    20.07 │     1.33 │     59.66 │    31.15 │     26.25 │    22.92 │
│    Token │          │          │           │          │           │          │
│ Through… │          │          │           │          │           │          │
│ Per User │          │          │           │          │           │          │
│ (tokens… │          │          │           │          │           │          │
│   Output │   994.99 │   262.00 │  1,004.00 │ 1,000.00 │    999.00 │   999.00 │
│ Sequence │          │          │           │          │           │          │
│   Length │          │          │           │          │           │          │
│ (tokens) │          │          │           │          │           │          │
│    Input │ 10,100.… │ 10,100.… │ 10,102.00 │ 10,102.… │ 10,101.00 │ 10,101.… │
│ Sequence │          │          │           │          │           │          │
│   Length │          │          │           │          │           │          │
│ (tokens) │          │          │           │          │           │          │
│   Output │   661.18 │      N/A │       N/A │      N/A │       N/A │      N/A │
│    Token │          │          │           │          │           │          │
│ Through… │          │          │           │          │           │          │
│ (tokens… │          │          │           │          │           │          │
│  Request │     0.66 │      N/A │       N/A │      N/A │       N/A │      N/A │
│ Through… │          │          │           │          │           │          │
│     (per │          │          │           │          │           │          │
│     sec) │          │          │           │          │           │          │
│  Request │ 1,600.00 │      N/A │       N/A │      N/A │       N/A │      N/A │
│    Count │          │          │           │          │           │          │
│  (count) │          │          │           │          │           │          │
└──────────┴──────────┴──────────┴───────────┴──────────┴───────────┴──────────┘
[2025-11-01 18:06:02] INFO     Generating                    json_exporter.py:64
                               /tmp/simple_decode_test_400/_                    
                               home_bedicloud_models_deepsee                    
                               k-ai_DeepSeek-R1-Distill-Llam                    
                               a-70B-openai-chat-concurrency                    
                               400/profile_export_genai_perf                    
                               .json                                            
[2025-11-01 18:06:02] INFO     Generating                     csv_exporter.py:75
                               /tmp/simple_decode_test_400/_h                   
                               ome_bedicloud_models_deepseek-                   
                               ai_DeepSeek-R1-Distill-Llama-7                   
                               0B-openai-chat-concurrency400/                   
                               profile_export_genai_perf.csv                    

----------------------------------------

================================================================================
================================================================================
DECODE TEST RESULTS - Concurrency: 450
Timestamp: 2025-11-01 19:01:47
Model: /home/bedicloud/models/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
Service URL: http://127.0.0.1:8003
Input Length: 10000, Output Length: 1000
Status: SUCCESS
================================================================================

GENAI-PERF OUTPUT:
----------------------------------------
[2025-11-01 18:06:09] INFO     Detected passthrough args: ['-vv',  parser.py:865
                               '--max-threads=300']                             
[2025-11-01 18:06:09] INFO     Profiling these models:       create_config.py:58
                               /home/bedicloud/models/deepse                    
                               ek-ai/DeepSeek-R1-Distill-Lla                    
                               ma-70B                                           
[2025-11-01 18:06:09] INFO     Model name            perf_analyzer_config.py:157
                               '/home/bedicloud/mode                            
                               ls/deepseek-ai/DeepSe                            
                               ek-R1-Distill-Llama-7                            
                               0B' cannot be used to                            
                               create artifact                                  
                               directory. Instead,                              
                               '_home_bedicloud_mode                            
                               ls_deepseek-ai_DeepSe                            
                               ek-R1-Distill-Llama-7                            
                               0B' will be used.                                
[2025-11-01 18:06:09] INFO     Creating tokenizer for:         subcommand.py:190
                               /home/bedicloud/models/deepseek                  
                               -ai/DeepSeek-R1-Distill-Llama-7                  
                               0B                                               
[2025-11-01 18:06:13] INFO     Running Perf Analyzer :          subcommand.py:98
                               'perf_analyzer -m                                
                               /home/bedicloud/models/deepseek-                 
                               ai/DeepSeek-R1-Distill-Llama-70B                 
                                --async --stability-percentage                  
                               999 --request-count 1800 -i http                 
                               -u http://127.0.0.1:8003                         
                               --concurrency-range 450                          
                               --service-kind openai --endpoint                 
                               v1/chat/completions -vv                          
                               --max-threads=300 --input-data                   
                               /tmp/simple_decode_test_450/_hom                 
                               e_bedicloud_models_deepseek-ai_D                 
                               eepSeek-R1-Distill-Llama-70B-ope                 
                               nai-chat-concurrency450/inputs.j                 
                               son --profile-export-file                        
                               /tmp/simple_decode_test_450/_hom                 
                               e_bedicloud_models_deepseek-ai_D                 
                               eepSeek-R1-Distill-Llama-70B-ope                 
                               nai-chat-concurrency450/profile_                 
                               export.json'                                     
[2025-11-01 19:00:27] INFO     Loading response data   profile_data_parser.py:66
                               from                                             
                               '/tmp/simple_decode_tes                          
                               t_450/_home_bedicloud_m                          
                               odels_deepseek-ai_DeepS                          
                               eek-R1-Distill-Llama-70                          
                               B-openai-chat-concurren                          
                               cy450/profile_export.js                          
                               on'                                              
[2025-11-01 19:00:43] INFO     Parsing total 1800 llm_profile_data_parser.py:124
                               requests.                                        
                        NVIDIA GenAI-Perf | LLM Metrics                         
┏━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━┓
┃ Statist… ┃      avg ┃      min ┃       max ┃      p99 ┃       p90 ┃      p75 ┃
┡━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━┩
│  Time To │ 466,512… │ 29,195.… │ 642,280.… │ 630,427… │ 606,026.… │ 594,177… │
│    First │          │          │           │          │           │          │
│    Token │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│  Time To │ 7,185.68 │    33.54 │ 27,989.00 │ 24,111.… │ 17,482.10 │ 12,236.… │
│   Second │          │          │           │          │           │          │
│    Token │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│  Request │ 536,972… │ 75,473.… │ 1,253,89… │ 1,153,6… │ 660,456.… │ 654,262… │
│  Latency │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│    Inter │    70.69 │    32.49 │    664.95 │   624.54 │     60.83 │    57.25 │
│    Token │          │          │           │          │           │          │
│  Latency │          │          │           │          │           │          │
│     (ms) │          │          │           │          │           │          │
│   Output │    19.37 │     1.50 │     30.78 │    29.15 │     24.88 │    21.94 │
│    Token │          │          │           │          │           │          │
│ Through… │          │          │           │          │           │          │
│ Per User │          │          │           │          │           │          │
│ (tokens… │          │          │           │          │           │          │
│   Output │   997.48 │   671.00 │  1,002.00 │ 1,000.00 │    999.00 │   999.00 │
│ Sequence │          │          │           │          │           │          │
│   Length │          │          │           │          │           │          │
│ (tokens) │          │          │           │          │           │          │
│    Input │ 10,100.… │ 10,100.… │ 10,102.00 │ 10,102.… │ 10,101.00 │ 10,101.… │
│ Sequence │          │          │           │          │           │          │
│   Length │          │          │           │          │           │          │
│ (tokens) │          │          │           │          │           │          │
│   Output │   552.66 │      N/A │       N/A │      N/A │       N/A │      N/A │
│    Token │          │          │           │          │           │          │
│ Through… │          │          │           │          │           │          │
│ (tokens… │          │          │           │          │           │          │
│  Request │     0.55 │      N/A │       N/A │      N/A │       N/A │      N/A │
│ Through… │          │          │           │          │           │          │
│     (per │          │          │           │          │           │          │
│     sec) │          │          │           │          │           │          │
│  Request │ 1,800.00 │      N/A │       N/A │      N/A │       N/A │      N/A │
│    Count │          │          │           │          │           │          │
│  (count) │          │          │           │          │           │          │
└──────────┴──────────┴──────────┴───────────┴──────────┴───────────┴──────────┘
[2025-11-01 19:01:46] INFO     Generating                    json_exporter.py:64
                               /tmp/simple_decode_test_450/_                    
                               home_bedicloud_models_deepsee                    
                               k-ai_DeepSeek-R1-Distill-Llam                    
                               a-70B-openai-chat-concurrency                    
                               450/profile_export_genai_perf                    
                               .json                                            
[2025-11-01 19:01:46] INFO     Generating                     csv_exporter.py:75
                               /tmp/simple_decode_test_450/_h                   
                               ome_bedicloud_models_deepseek-                   
                               ai_DeepSeek-R1-Distill-Llama-7                   
                               0B-openai-chat-concurrency450/                   
                               profile_export_genai_perf.csv                    

----------------------------------------

================================================================================
