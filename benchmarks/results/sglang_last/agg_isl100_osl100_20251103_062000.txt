================================================================================
DECODE TEST RESULTS - Concurrency: 1
Timestamp: 2025-11-03 06:20:13
Model: /raid5/models/deepseek-ai/DeepSeek-R1-Distill-Llama-8B
Service URL: http://127.0.0.1:8003
Input Length: 100, Output Length: 100
Status: SUCCESS
================================================================================

GENAI-PERF OUTPUT:
----------------------------------------
[2025-11-03 06:20:01] INFO     Detected passthrough args: ['-vv', '--max-threads=300']                                parser.py:865
[2025-11-03 06:20:01] INFO     Profiling these models: /raid5/models/deepseek-ai/DeepSeek-R1-Distill-Llama-8B   create_config.py:58
[2025-11-03 06:20:01] INFO     Model name '/raid5/models/deepseek-ai/DeepSeek-R1-Distill-Llama-8B'      perf_analyzer_config.py:157
                               cannot be used to create artifact directory. Instead,                                               
                               '_raid5_models_deepseek-ai_DeepSeek-R1-Distill-Llama-8B' will be used.                              
[2025-11-03 06:20:01] INFO     Creating tokenizer for: /raid5/models/deepseek-ai/DeepSeek-R1-Distill-Llama-8B     subcommand.py:190
[2025-11-03 06:20:04] INFO     Running Perf Analyzer : 'perf_analyzer -m                                           subcommand.py:98
                               /raid5/models/deepseek-ai/DeepSeek-R1-Distill-Llama-8B --async                                      
                               --stability-percentage 999 --request-count 4 -i http -u http://127.0.0.1:8003                       
                               --concurrency-range 1 --service-kind openai --endpoint v1/chat/completions -vv                      
                               --max-threads=300 --input-data                                                                      
                               /tmp/simple_decode_test_1/_raid5_models_deepseek-ai_DeepSeek-R1-Distill-Llama-8B-op                 
                               enai-chat-concurrency1/inputs.json --profile-export-file                                            
                               /tmp/simple_decode_test_1/_raid5_models_deepseek-ai_DeepSeek-R1-Distill-Llama-8B-op                 
                               enai-chat-concurrency1/profile_export.json'                                                         
[2025-11-03 06:20:07] INFO     Loading response data from                                                 profile_data_parser.py:66
                               '/tmp/simple_decode_test_1/_raid5_models_deepseek-ai_DeepSeek-R1-Distill-L                          
                               lama-8B-openai-chat-concurrency1/profile_export.json'                                               
[2025-11-03 06:20:07] INFO     Parsing total 4 requests.                                             llm_profile_data_parser.py:124
                               NVIDIA GenAI-Perf | LLM Metrics                                
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━┓
┃                            Statistic ┃    avg ┃    min ┃    max ┃    p99 ┃    p90 ┃    p75 ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━┩
│             Time To First Token (ms) │  36.60 │  34.18 │  42.70 │  42.48 │  40.47 │  37.11 │
│            Time To Second Token (ms) │   5.86 │   5.67 │   6.22 │   6.20 │   6.09 │   5.89 │
│                 Request Latency (ms) │ 680.52 │ 668.61 │ 690.15 │ 689.90 │ 687.68 │ 683.98 │
│             Inter Token Latency (ms) │   6.57 │   6.46 │   6.61 │   6.61 │   6.61 │   6.61 │
│     Output Token Throughput Per User │ 152.21 │ 151.32 │ 154.73 │ 154.63 │ 153.73 │ 152.24 │
│                    (tokens/sec/user) │        │        │        │        │        │        │
│      Output Sequence Length (tokens) │  99.00 │  99.00 │  99.00 │  99.00 │  99.00 │  99.00 │
│       Input Sequence Length (tokens) │ 201.00 │ 201.00 │ 201.00 │ 201.00 │ 201.00 │ 201.00 │
│ Output Token Throughput (tokens/sec) │ 144.38 │    N/A │    N/A │    N/A │    N/A │    N/A │
│         Request Throughput (per sec) │   1.46 │    N/A │    N/A │    N/A │    N/A │    N/A │
│                Request Count (count) │   4.00 │    N/A │    N/A │    N/A │    N/A │    N/A │
└──────────────────────────────────────┴────────┴────────┴────────┴────────┴────────┴────────┘
[2025-11-03 06:20:12] INFO     Generating                                                                       json_exporter.py:64
                               /tmp/simple_decode_test_1/_raid5_models_deepseek-ai_DeepSeek-R1-Distill-Llama-8B                    
                               -openai-chat-concurrency1/profile_export_genai_perf.json                                            
[2025-11-03 06:20:12] INFO     Generating                                                                        csv_exporter.py:75
                               /tmp/simple_decode_test_1/_raid5_models_deepseek-ai_DeepSeek-R1-Distill-Llama-8B-                   
                               openai-chat-concurrency1/profile_export_genai_perf.csv                                              

----------------------------------------

================================================================================
